[
  {
    "objectID": "packagemanager.html",
    "href": "packagemanager.html",
    "title": "3  Package Manager",
    "section": "",
    "text": "3.1 Introduction - What is Package Manager\nPosit Package Manager provides a secure, reliable, and scalable way to distribute and manage R and Python packages across Dash.\nIn a nutshell, when wanting to install libraries, you can just do it through your console and libraries are fetch through package manager from cran, pyp, bioconductor even from Github !!, without needing to go through individual repository on internet. All in one package!",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package Manager</span>"
    ]
  },
  {
    "objectID": "packagemanager.html#what-can-package-manager-do",
    "href": "packagemanager.html#what-can-package-manager-do",
    "title": "3  Package Manager",
    "section": "3.2 What can Package Manager do?",
    "text": "3.2 What can Package Manager do?\nIn context of Dash, Package Manager can do the following:\n\nSearch and install packages from CRAN, PyPI, and Bioconductor and even from Github - will showcase each bellow\nMirror public repositories inside your own firewall, even offline\nAdd your own internal packages and binaries\nImprove security by blocking high-risk and unwanted packages\n\nThe list isn’t exhaustive for what Package Manager is able to achieve. For example curating subsets of CRAN and PyPI into custom repositories is something that can be done. Yet, we haven’t curated a list of libraries so that we allow users to download freely without any obstacles the desired libraries into their own environments. This is an advantage since a lot of libraries get updated.\nFurthermore, if there is a library the presents high-risk for Dash platform, this is flagged in Package Manager and cannot be downloaded into your own environment.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package Manager</span>"
    ]
  },
  {
    "objectID": "packagemanager.html#how-to-search-libraries-and-install-packages",
    "href": "packagemanager.html#how-to-search-libraries-and-install-packages",
    "title": "3  Package Manager",
    "section": "3.3 How to search libraries and install packages?",
    "text": "3.3 How to search libraries and install packages?\nOpen the link: https://dash-pkmgr-prd.azure.defra.cloud/\nIf selecting the down arrow, you’ll be able to see the repositories where libraries can be found.\n\n\n\n\n\n\n\n\n\n\n3.3.1 Searching for cran libraries and installation\nSearching for dplyr library when choosing cran repository shows the way to install, any metadata and security issues. If there are no security issues / vulnerabilities then installation into R environment will show no problems. Copy the code and go in RStudio IDE on Workbench and paste it into the console for installation to take effect.\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Searching for pyp libraries and installation\nSearching for pandas library when choosing pyp repository shows the way to install, any metadata and security issues. If there are no security issues / vulnerabilities then installation into Python environment will show no problems. Copy the code and go into IDE of your choice,on Workbench where Python can be accessed, and paste it into terminal for installation to take effect.\n\n\n\n\n\n\n\n\n\n\n\n3.3.3 Searching for bioconductor libraries and installation\nSearching for a4 library when choosing bioconductor repository shows the way to install, any metadata and security issues. If there are no security issues / vulnerabilities then installation into R environment will show no problems. Copy the code and go in RStudio IDE on Workbench and paste it into the console for installation to take effect.\n\n\n\n\n\n\n\n\n\n\n\n3.3.4 Searching for libraries on github and installation\nSearching for sdg library when choosing git-python repository shows the way to install, any metadata and security issues. If there are no security issues / vulnerabilities then installation into Python environment will show no problems. Copy the code and go into IDE of your choice,on Workbench where Python can be accessed, and paste it into terminal for installation to take effect.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package Manager</span>"
    ]
  },
  {
    "objectID": "workbench.html",
    "href": "workbench.html",
    "title": "2  Posit Workbench",
    "section": "",
    "text": "2.1 RStudio on Workbench\nUsername characters warning\nApostrophes and non-ASCII characters cannot be used in RStudio usernames; i.e. if your username is dara.óbriain@defra.gov.uk or bobby.o'brien@defra.gov.uk, it will not work. Please contact dashplatformsupport@defra.gov.uk for help.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Posit Workbench</span>"
    ]
  },
  {
    "objectID": "workbench.html#tutorials",
    "href": "workbench.html#tutorials",
    "title": "2  Posit Workbench",
    "section": "",
    "text": "2.1.1 Accessing RStudio\n\nLogin into Dash Workbench - https://dash-workbench-dev.azure.defra.cloud/\nA Single Sign On will come up. It will recognize your profile, yet if prompted to add your credentials then do it.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis will open RStudio Pro. If you work with Databricks then select the Databricks tab underneath RStudio under Session Credentials.\n\n\n\n\n\n\n\n\n\n\n\n2.1.1.1 Username characters warning\nApostrophes and non-ASCII characters cannot be used in RStudio usernames; i.e. if your username is dara.óbriain@defra.gov.uk or bobby.o'brien@defra.gov.uk, it will not work. Please contact dashplatformsupport@defra.gov.uk for help.\n\n\n\n2.1.2 Quitting a session and signing out\nIf you close the RStudio window but keep other tabs in the browser open, and then reopen RStudio through Databricks, your username and password will be saved and it takes you straight back to RStudio.\nTo sign out of RStudio on the DASH Platform, click on the Sign out icon next to your username at the top right hand side of your screen. You will need to enter your username and password again to get into RStudio, but your console and environment won’t be cleared. Please sign out when you are finished working in RStudio on the platform.\nIf you click on the orange Quit current R session icon also at the top right, you will close the current session, including clearing your console and environment.Quitting RStudio",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Posit Workbench</span>"
    ]
  },
  {
    "objectID": "workbench.html#rstudio-data",
    "href": "workbench.html#rstudio-data",
    "title": "2  Posit Workbench",
    "section": "2.2 Working with data",
    "text": "2.2 Working with data\n\n2.2.1 R Studio workspace\nWhen working in RStudio on the DASH Platform it is possible to upload files directly into your RStudio workspace through the upload button in the Files pane. This should only be used to load un-restricted data items. Your personal workspace in RStudio, including code, files, and data, should be treated as transient since this may be cleared if the cluster is restarted (which happens periodically to refresh the configuration).\nAny important data should be transferred to the Lab zone in the data lake, see the data lake chapter.\nAny code or documentation should be backed up in a GitHub repository, see GitHub section.\n\n\n\n\n\n\nImportant\n\n\n\nIt is important that you back up any files you keep in your DASH Platform R workspace, and the recommendation is to do so using GitHub to host your code and outputs. You can also export file to your local machine. Otherwise you may lose your work if there is a restart of the RStudio cluster. Save any data in your folder in the lab zone as detailed in the data lake chapter.\n\n\n\n\n2.2.2 Backing up your workspace\nWhenever the RStudio cluster you are using is restarted, all your files are wiped from your RStudio workspace. We will let you know ahead of scheduled cluster restarts, but it is also possible that the cluster needs to be restarted unexpectedly.\nTherefore you need to back up your work on a regular basis. The recommended way is to do so via GitHub, see section x\nIf you can’t back up your files via GitHub, it is also possible to download scripts and outputs such as figures to your local machine.\n\nOn the right hand side under Files, select the files you want to download to your local machine\n\nClick on More &gt; Export…\n\nRename the files if required, then click Download\n\nThe files will appear in your Downloads folder on your local machine\n\n\n\n2.2.3 Working with data\nRead data from Unity Catalog\nThere are several ways to read data from Databricks. One is through brickster library and the other is through sparklyr library. I will showcase each bellow.\nTo read Volume data from Databricks from Unity Catalog first check if you have access to data you intend to work with.\n\nLogin into Databricks\nGo to Catalog\nSee under My Organisation & Delta Shares Received\n\nRead data with brickster (see link https://databrickslabs.github.io/brickster/articles/setup-auth.html )\nAs I have access to data and want to read volume data, I run the code in R file in RStudio\nlibrary(brickster)\n \n# read a volume, change the path\nfile &lt;- db_volume_read(\n  '/Volumes/tst1_dash_lab/soundscapes_restricted/shared_external_volume/penguins.csv',\n  tempfile(),\n  perform_request = TRUE)\n \npenguins &lt;- read.csv(file)\nx    &lt;- penguins$body_mass_g\nprint(x)\n \ngentoo &lt;- subset(penguins, species == \"Gentoo\")\nprint(gentoo)\n \ngentoo &lt;- subset(penguins, species == \"Gentoo\")\n \nAnd to save data do the bellow into RStudio work space\nwrite.csv(gentoo,\"gentoo.csv\", row.names = FALSE)\nIf you want to save the gentoo data back to Volume but distinct from penguin.csv from which was derived then do this:\ndb_volume_write(\n  '/Volumes/tst1_dash_lab/soundscapes_restricted/shared_external_volume/gentoo.csv',\n  'gentoo.csv',\n  overwrite = TRUE,\n  perform_request = TRUE)\nReading data with sparklyr (see link https://www.databricks.com/glossary/sparklyr ).\nBefore reading the data, first we need to connect to Databricks.\n\nFirst login into Workspace and select RStudio and select Databricks\n\n\n\n\n\n\n\n\n\n\n\nNow you’re signed in. On the right hand side, you need to see a tab - Databricks - and see the clusters. I have 4 of them. This means there is no need for any credentials, RStudio does that for you. Now you want to make your way to data.\n\n\n\n\n\n\n\n\n\n\n\nRead data by passing the Cluster id into spark_connect function and also the version. Copy the code bellow and replace the parameters with the ones you get once logged in.\n\n\n\n\n\n\n\n\n\n\nlibrary(sparklyr)\nlibrary(pysparklyr)\n\n# Use an all purpose cluster\nsc &lt;- spark_connect(\n  cluster_id = \"0717-160441-e0z99iuh\",\n  method = \"databricks_connect\", \n  version = \"17.0\"\n)\n\nThe other way to is to use serveless cluster, where there is no need to add any cluster ID as this is managed for you already.\n\n# Use serverless cluster -\nlibrary(sparklyr)\nlibrary(pysparklyr)\n\nsc &lt;- spark_connect(\n  serverless = TRUE,\n  method = \"databricks_connect\", \n  version = \"15.4\"\n)\nAs you’ve made your way to the clusters now we need to read data\n# Set the database where the table is located\ndatabase_name &lt;- \"shared_external_volume\"\n\n# Use spark_read_table() function to read the table\ndata_tbl &lt;- spark_read_table(sc, in_database(database_name, \"gentoo.csv\"))",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Posit Workbench</span>"
    ]
  },
  {
    "objectID": "workbench.html#faqs",
    "href": "workbench.html#faqs",
    "title": "2  Posit Workbench",
    "section": "2.3 FAQs",
    "text": "2.3 FAQs\n\n2.3.1 R version\nThere are multiple versions of R=(“4.4.2” “4.4.0” “4.3.2” “4.3.1” “4.3.0” “4.2.2”) . To check versions of R press down arrow and you should see the versions.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Posit Workbench</span>"
    ]
  },
  {
    "objectID": "workbench.html#visual-code-on-workbench",
    "href": "workbench.html#visual-code-on-workbench",
    "title": "2  Posit Workbench",
    "section": "2.2 Visual Code on Workbench",
    "text": "2.2 Visual Code on Workbench\nVS Code on Workbench integrated with Databricks simplifies authentification process as it is done through Databricks OAuth credentials.\nSelect VS Code and select Databricks connection under Session Credentials.\n\n\n\n\n\n\n\n\n\nAs you can see on the right hand side in the corner there is a Databricks connection setup for you.\n\n\n\n\n\n\n\n\n\n\n2.2.1 Installing Extension\nVS Code on Workbench does allow for extensions to be installed but with a caveat. You need to configure first the Application proxy SSL in order to be able to achieve the installations. Follow the steps bellow:\n\nGo to Settings -&gt; Remote[dash-workbench-prd-azure.defra.cloud]\nSearch for SSL\nChoose Application -&gt; Proxy and un-thick the box for Http: Proxy Strict SSL.\n\n\n\n\n\n\n\n\n\n\nAn example using SQL database installation:\nGo to Extensions and search for Sql you should be able to install and use sql database.\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Version Control (Git)\nIf you haven’t authorised VS Code with Git, then it is necessary to follow the next steps so that in the future you won’t need to configure it. Follow the steps bellow.\n\nGo to Explorer -&gt; Clone Repository\n\n\n\n\n\n\n\n\n\n\n\nPress Allow\n\n\n\n\n\n\n\n\n\n\n\nA code to Copy will show up -&gt; Copy and Continue to Github\n\n\n\n\n\n\n\n\n\n\n\nYou have to be logged into Github first. Press Open.\n\n\n\n\n\n\n\n\n\n\n\nCopy the one time code to paste into next window\n\n\n\n\n\n\n\n\n\n\n6.Paste the code. If you cannot , go back and copy again the code and follow the same.\n\n\n\n\n\n\n\n\n\n\nScroll down and Authorise Visual Code\n\n\n\n\n\n\n\n\n\n\n\nNow go back to Visual Code and you should be able to see all the repositories you own on Github.\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.3 Installing python libraries\nPython libraries in VS Code can be installed. Dash has configured Package Manager where the libraries would be installed from.\nPackage manager provides a secure, reliable, and scalable way to distribute and manage Python packages across Dash. Check the Package Manager section for more information. Check the section within Dash Playbook bellow or navigate to Dash Package Manager.\n\n2.2.3.0.1 How to install python libaries?\nYet, it is important to work with virtual environments, within your project folder when installing libraries. Otherwise you’ll get error when attempting to achieve this task. For example you’ll get the following error relating to asking your admin:\n pip install pandas \n   Command 'pip' not found, but can be installed with: \n   apt install python3-pip \n   Please ask your administrator.\n\n\n2.2.3.0.2 Steps in setting up virtual environments\nOpen a terminal within VS Code on Workbench and follow the steps bellow.\n\nCreate a virtual environment\n\npython3 -m venv venv\n\nActivate the virtual environment\nsource venv/bin/activate\nInstall the libraries needed using pip\npip install rsconnect\nor if you have a txt file with the versions of the libraries you might need,then use the bellow command\npip install -r requirements.txt \n\nIf you get an error in installing any library from python, then copy the library and version you get error, and check it within Package Manager . You might get some information as to why you aren’t able to get the installation complete.\n\n\n\n2.2.4 Working with data in VS Code\nRead data from Unity Catalog\nTo read Volume data from Databricks from Unity Catalog first check if you have access to data you intend to work with.\n\nLogin into Databricks\nGo to Catalog\nYou should see data under My Organisation & Delta Shares Received\n\nAs I have access to data and want to read volume data, and transform it into pandas data frame will use this as a case study. However, in workspace client there is no need to add the HOST and Token variables as this was already done automatically for you.\n# Import required packages  \nimport pandas as pd \nfrom databricks.sdk \nimport WorkspaceClient from io import BytesIO \n\n# Set up workspace connection \nw = WorkspaceClient() \n\n# Read file from UNity catalog volume \nresponse = w.files.download(\"/Volumes/tst1_dash_lab/soundscapes_restricted/shared_external_volume/penguins.csv\")\n\ndownloaded_file = response.contents.read()\n\n# Read downloaded file to Pandas dataframe. \ndf = pd.read_csv(BytesIO(downloaded_file))\n\n# Open file to upload \nadelie = df[df['species'] == 'Adelie']\n\nadelie.to_csv(\"/tmp/adelie.csv\", index=False)\nYou can also write file to Unity Catalog Volume\n# Write file to Unity Catalog Volume  \n\nwith open(\"/tmp/adelie.csv\", \"rb\") as f:     \n  csv = f.read() \n  \nw.files.upload(\"/Volumes/tst1_dash_lab/soundscapes_restricted/shared_external_volume/adelie.csv\", csv)",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Posit Workbench</span>"
    ]
  },
  {
    "objectID": "workbench.html#migration-of-projects-to-workbench",
    "href": "workbench.html#migration-of-projects-to-workbench",
    "title": "2  Posit Workbench",
    "section": "2.5 Migration of projects to Workbench",
    "text": "2.5 Migration of projects to Workbench\nThere are two methods for migrating projects from different old IDE’s to Workbench\na. By Exporting the project folder from RStudio (Databricks) and Uploading the zipped by choosing ’Choose File’ into RStudio Workbench.\n\n\n\n\n\n\n\n\n\nb. By using Version Control - Github. For this you need to have Github handle. See bellow steps for Steps in R projects migration and Steps in Python project migration\n\n2.5.1 Steps in R projects migration\n\nIf you have Version Control (Github) set up on your project, jump straight to Step 13 within this page. If you did not have Version Control applied to the projects in RStudio then it is necessary to create a New Repository using the Defra Data Science Centre of Excellence GitHub.\n\n\n\n\n\n\n\n\n\n\n\nGive an intuitive unique name to the new repo. Make sure the new repo is ticked as Internal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPress Create repository\n\n\n\n\n\n\n\n\n\n\n\nGo to the Home directory in RStudio Databricks.\nNavigate to File -&gt; New Project -&gt; Version Control\n\n\n\n\n\n\n\n\n\n\n\nSelect Git\n\n\n\n\n\n\n\n\n\n\n\nAdd in the repository URL link obtained from Github - see second picture where to copy the link from. Make sure it is an HTTPS link.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdd the link obtained above into Repository URL\n\n\n\n\n\n\n\n\n\n\n\nChoose the R Version your project was developed in. The R Version will depend on the Databricks Runtime. You can find out the version by typing version in the console.\n\n\n\n\n\n\n\n\n\n\n\nAdd your Github username and Personal Access token (see second picture).\n\n\n\n\n\n\n\nObtain Personal Access Token\n\n\n\nThe Personal Access token can be obtained By going to GitHub Profile, Settings, Developer section. Choose the type of token you want. Copy the token, saved it safely as this token cannot be seen again. And paste it into ‘RStudio Personal access token’ tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter completing the steps above the new project is set locally, into RStudio Databricks, just as below.\n\nNavigate into the older project and copy all files from the project into new repo created. At this stage Version Control is now applied to your project.\nYou now need to push onto Github, under your repo. Before pushing to Github make sure the code / app / etc works.\n\n\n\n\n\n\n\n\n\n\nGo to Git tab within RStudio you’ll see some files to be pushed onto Github.\n\n\n\n\n\n\n\nImportant\n\n\n\nBefore you commit, make sure you gitignore sensitive data, and check the files are safe to be pushed on Github.\nTick all the files (not data or any folder containing sensitive data) and press Commit. Add a note to remind you what is the commit about.\nPress Push button under Git tab. Then navigate to Github repo and check if all the files are there. These files should be there.\n\n\n\n\n\n\n\n\n\n\n\n\nOpen the Workbench .Select RStudio -&gt; Start Session to open RStudio IDE.\n\n\n\n\n\n\n\n\n\n\n\nGo to Github, to the new repo created/existing repo (make sure the project is pushed to Github), and copy the HTTPS link\n\n\n\n\n\n\n\n\n\n\n\nIn RStudio Workbench, Drop down File -&gt; New Project\n\n\n\n\n\n\n\n\n\n\n\nChoose Version Control\n\n\n\n\n\n\n\n\n\n\n\nChoose Git\n\n\n\n\n\n\n\n\n\n\n\nPaste the HTTPS repo url within Repository url section\n\n\n\n\n\n\n\n\n\n\n\nChoose which R Version the project was created and Push Create Project\n\n\n\n\n\n\n\n\n\n\n\nAnd finally, the project is now migrated into the new Workbench RStudio.\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.2 Steps in Python project migration\n\nIf you have Version Control (Github) set up on your project, go to Step 16 for the actual project to be pulled into Posit Workbench. If you do not have a Version Control functionality applied to the python projects then it is necessary to create a New Repository under https://github.com/Defra-Data-Science-Centre-of-Excellence.\n\n\n\n\n\n\n\n\n\n\n\nGive an intuitive unique name to the new repo. Make sure the new repo is ticked as Internal (within ‘Choose visibility’ section).\n\n\n\n\n\n\n\n\n\n\n\nPress Create repository\n\n\n\n\n\n\n\n\n\n\n\nAnd the repo is created under Defra-Data-Science-Centre-Of-Excellence project \n\n\n\n\n\n\n\n\n\n\n\nThen open VSCode and press Clone Repository.\n\n\n\n\n\n\n\n\n\n\n\nA ‘Clone from Github’ message will appear\n\n\n\n\n\n\n\n\n\n\n\nIf you are signed into Github, then it will automatically recognise the repositories created by you just as below. Choose the repo you have created above.\n\n\n\n\n\n\n\n\n\n\n\nChoose a folder to clone\n\n\n\n\n\n\n\n\n\n\n\nOpen the cloned repository\n\n\n\n\n\n\n\n\n\n\n\nThe cloned repository should be empty. Right click and Add Folder to Workspace\n\n\n\n\n\n\n\n\n\n\n\nI selected all the files you want to add and press open\n\n\n\n\n\n\n\n\n\n\n\nSelect ‘Yes’ to committing the changes. Then add some text within the Changes tab and press Commit.\n\n\n\n\n\n\n\n\n\n\n\nA message will appear saying ’Make sure you configure your “user.name” and “user.email” in git. Go to the terminal, within VSCode and add you defra username and your name:\n$ git config --global user.name \"John Doe\"\n$ git config --global user.email johndoe@example.com\nNOTE: More information about adding your credentials - at this link - https://git-scm.com/book/en/v2/Getting-Started-First-Time-Git-Setup\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThen select Push - this will push it to Github. If you navigate to your repo on Github, you should then see your local changes to the repo to Github.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs the project is now on Github, go to Workbench https://dash-workbench-dev.azure.defra.cloud/ and pull the project into the new workspace.\nOpen the VS Code.\n\n\n\n\n\n\n\n\n\n\n\nChoose Initialise Repository.\n\n\n\n\n\n\n\n\n\n\n\nA new window comes up and choose allow.\n\n\n\n\n\n\n\n\n\n\n\nCopy the code and Certificate to Github\n\n\n\n\n\n\n\n\n\n\n\nPress Open and as signed into Github a Device Activation will come up.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaste the code you’ve copied above.\n\n\n\n\n\n\n\n\n\n\n\nChoose Clone repository\n\n\n\n\n\n\n\n\n\n\n\nA new tab ‘The extension Github wants to sign in Github’ should come up. Choose allow.\n\n\n\n\n\n\n\n\n\n\n\nPress Authorise Visual-Studio-Code.\n\n\n\n\n\n\n\n\n\n\n\nGitHub will ask for Authentication through the autheticator app.\n\n\n\n\n\n\n\n\n\n\n\nA confirmation in format as bellow should come up. Now you can use VSCode within Workbench to apply Git Version control functionality to your projects.\n\n\n\n\n\n\n\n\n\n\n\nIf still signed into Github (which you will since the above has confirmed the configuration) choose the project to be cloned into Workbench.\n\n\n\n\n\n\n\n\n\n\n\nAnd tick the box trust the authors.\n\n\n\n\n\n\n\n\n\n\n\nOpen the cloned repository. After opening, you should see migrated project within workbench.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Posit Workbench</span>"
    ]
  },
  {
    "objectID": "workbench.html#rstudio-on-workbench",
    "href": "workbench.html#rstudio-on-workbench",
    "title": "2  Posit Workbench",
    "section": "",
    "text": "Login into Dash Workbench - https://dash-workbench-dev.azure.defra.cloud/\nA Single Sign On will come up. It will recognize your profile, yet if prompted to add your credentials then do it.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis will open RStudio Pro. If you work with Databricks then select the Databricks tab underneath RStudio under Session Credentials.\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.1 Quitting a session and signing out\nIf you close the RStudio window but keep other tabs in the browser open, and then reopen RStudio through Databricks, your username and password will be saved and it takes you straight back to RStudio.\nTo sign out of RStudio on the DASH Platform, click on the Sign out icon next to your username at the top right hand side of your screen. You will need to enter your username and password again to get into RStudio, but your console and environment won’t be cleared. Please sign out when you are finished working in RStudio on the platform.\nIf you click on the orange Quit current R session icon also at the top right, you will close the current session, including clearing your console and environment.Quitting RStudio\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Working with data\n\n2.1.2.1 R Studio workspace\nWhen working in RStudio on the DASH Platform it is possible to upload files directly into your RStudio workspace through the upload button in the Files pane. This should only be used to load un-restricted data items. Your personal workspace in RStudio, including code, files, and data, should be treated as transient since this may be cleared if the cluster is restarted (which happens periodically to refresh the configuration).\nAny important data should be transferred to the Lab zone in the data lake, see the data lake chapter.\nAny code or documentation should be backed up in a GitHub repository, see GitHub section.\n\n\n\n\n\n\nImportant\n\n\n\nIt is important that you back up any files you keep in your DASH Platform R workspace, and the recommendation is to do so using GitHub to host your code and outputs. You can also export file to your local machine. Otherwise you may lose your work if there is a restart of the RStudio cluster. Save any data in your folder in the lab zone as detailed in the data lake chapter.\n\n\n\n\n2.1.2.2 Backing up your workspace\nWhenever the RStudio cluster you are using is restarted, all your files are wiped from your RStudio workspace. We will let you know ahead of scheduled cluster restarts, but it is also possible that the cluster needs to be restarted unexpectedly.\nTherefore you need to back up your work on a regular basis. The recommended way is to do so via GitHub, see section x\nIf you can’t back up your files via GitHub, it is also possible to download scripts and outputs such as figures to your local machine.\n\nOn the right hand side under Files, select the files you want to download to your local machine\n\nClick on More &gt; Export…\n\nRename the files if required, then click Download\n\nThe files will appear in your Downloads folder on your local machine\n\n\n\n2.1.2.3 Read data from Databricks\nThere are several ways to read data from Databricks. One is through brickster library and the other is through sparklyr library. I will showcase each bellow.\nTo read Volume data from Databricks from Unity Catalog first check if you have access to data you intend to work with.\n\nLogin into Databricks\nGo to Catalog\nSee under My Organisation & Delta Shares Received\n\nRead data with brickster (see link https://databrickslabs.github.io/brickster/articles/setup-auth.html )\nAs I have access to data and want to read volume data, I run the code in R file in RStudio\nlibrary(brickster)\n \n# read a volume, change the path\nfile &lt;- db_volume_read(\n  '/Volumes/tst1_dash_lab/soundscapes_restricted/shared_external_volume/penguins.csv',\n  tempfile(),\n  perform_request = TRUE)\n \npenguins &lt;- read.csv(file)\nx    &lt;- penguins$body_mass_g\nprint(x)\n \ngentoo &lt;- subset(penguins, species == \"Gentoo\")\nprint(gentoo)\n \ngentoo &lt;- subset(penguins, species == \"Gentoo\")\n \nAnd to save data do the bellow into RStudio work space\nwrite.csv(gentoo,\"gentoo.csv\", row.names = FALSE)\nIf you want to save the gentoo data back to Volume but distinct from penguin.csv from which was derived then do this:\ndb_volume_write(\n  '/Volumes/tst1_dash_lab/soundscapes_restricted/shared_external_volume/gentoo.csv',\n  'gentoo.csv',\n  overwrite = TRUE,\n  perform_request = TRUE)\nReading data with sparklyr (see link https://www.databricks.com/glossary/sparklyr ).\nBefore reading the data, first we need to connect to Databricks.\n\nFirst login into Workspace and select RStudio and select Databricks\n\n\n\n\n\n\n\n\n\n\n\nNow you’re signed in. On the right hand side, you need to see a tab - Databricks - and see the clusters. I have 4 of them. This means there is no need for any credentials, RStudio does that for you. Now you want to make your way to data.\n\n\n\n\n\n\n\n\n\n\n\nRead data by passing the Cluster id into spark_connect function and also the version. Copy the code bellow and replace the parameters with the ones you get once logged in.\n\n\n\n\n\n\n\n\n\n\nlibrary(sparklyr)\nlibrary(pysparklyr)\n\n# Use an all purpose cluster\nsc &lt;- spark_connect(\n  cluster_id = \"0717-160441-e0z99iuh\",\n  method = \"databricks_connect\", \n  version = \"17.0\"\n)\n\nThe other way to is to use serveless cluster, where there is no need to add any cluster ID as this is managed for you already.\n\n# Use serverless cluster -\nlibrary(sparklyr)\nlibrary(pysparklyr)\n\nsc &lt;- spark_connect(\n  serverless = TRUE,\n  method = \"databricks_connect\", \n  version = \"17.0\"\n)\nSomething like that should appear in the Connections tab on RStudio.\n\n\n\n\n\n\n\n\n\nAs you’ve made your way to the clusters now we need to read data\n# Set the database where the table is located\ndatabase_name &lt;- \"the_name_of_the_database_you_haveaccess\"\n\n# Use spark_read_table() function to read the table gentoo for example\ndata_tbl &lt;- spark_read_table(sc, in_database(database_name, \"gentoo.csv\"))\n\n\n2.1.2.4 FAQs\n\n\n2.1.2.5 R version\nThere are multiple versions of R=(“4.4.2” “4.4.0” “4.3.2” “4.3.1” “4.3.0” “4.2.2”) . To check versions of R press down arrow and you should see the versions.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Posit Workbench</span>"
    ]
  },
  {
    "objectID": "posit_connect.html",
    "href": "posit_connect.html",
    "title": "1  Posit Connect Server",
    "section": "",
    "text": "1.1 Tutorials",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Posit Connect Server</span>"
    ]
  },
  {
    "objectID": "posit_connect.html#tutorials",
    "href": "posit_connect.html#tutorials",
    "title": "1  Posit Connect Server",
    "section": "",
    "text": "1.1.1 How to access Posit Connect\nAccess the Posit Connect server here to login. When asked to log in with your PAM credentials, use your Defra Windows details. Login is done using Single Sign On (SSO). This is a feature that allows users to access the platform using their existing DEFRA login credentials, unlike previous way of needing a separate username and password for Connect.\n\n\n\n\n\nPosit login screen\n\n\n\n\nLogging in is important so you can be assigned permissions for restricted content. Until you have logged in for first time, it won’t be possible for creators to assign you access to relevant dashboards.\n\n\n1.1.2 Sharing content\nDASH users or DASH content viewers will be given a log in for the Posit connect application.\nIndividual dashboards can be set to be viewed by:\n\n“Anyone, no login required” – This includes anyone within the Defra firewall and all users that have been on-boarded onto DASH.\n\nUsers from Core Defra, Environment Agency (EA), Joint Nature Conservation Committee (JNCC), Marine Management Organisation (MMO), Natural England (NE), and Rural Payments Agency (RPA) can view Posit Connect dashboards via their own Defra devices.\nNon-core Defra users will only be able to view Posit Connect dashboards via a DASH AVD (Azure Virtual Desktop).\n\n“All users - login required”\n“Specific users groups”\n\nPublishers can share a URL with users to view specific content. To enable a Publisher to give access to a specific user, that user must have previously logged onto the server at least once.\nInstruction on using a dashboard itself is the responsibility of the dashboard owners.\n\n\n1.1.3 User roles\nPosit server users can be “Administrators”, “Publishers” or “Viewers”.\nAdministrators\nInstructions for the Administrators role is beyond the scope of this document.\nPublishers\nAble to publish content to be hosted onto the server. They can also select access options for published content.\nDASH users are given publishing access on request.\n\nIf you would like to be upgraded from Viewer to Publisher, please email dashplatformsupport@defra.gov.uk with:\n\n\nSubject: Request Publisher access to Posit Server\n\nInclude your Defra (or ALB) email address in the message body.\nViewers\nAble to view and use the published content. DASH users are given Viewer access by default.\nViewers should request access through a MyIT request.\n\n\n1.1.4 Publishing\n\n\n\n\n\n\nImportant\n\n\n\nPlease ensure any data published to RStudio connect is only accessible to users who should have access to that data.\nFor data in the data lake, please refer to the Data Catalogue for restrictions.\n\n\n\n1.1.4.1 Publishing from RStudio\nShiny dashboards as well as R Markdown and bookdown files can be published directly from RStudio server.\nThe below process will use the example Shiny dashboard in RStudio. The same process would be followed for other types of files to be published.\nThere is a 2GB limit to the size of dashboards that can be published on the Posit server.\nFirst access RStudio from Dash Platform on Databricks / Workbench (here is the link for new server where RStudio sits - https://dash-workbench-prd.azure.defra.cloud/ - which will replace the RStudio within Databricks).\nOn Workbench choose RStudio Pro, and check the Session Credential tab if you read data from Databricks.\n\n\n\n\n\n\n\n\n\n\n1.1.4.1.1 Create a Dasboard\nDrop down File -&gt; Choose Shiny Web App\n\n\n\n\n\n\n\n\n\nFrom this give the dashboard a name and click Create\n\n\n\n\n\n\n\n\n\n\n\n1.1.4.1.2 Connect to Posit server\nNext go to the top right of the window and click Publish Application\n\n\n\n\n\n\n\n\n\nIf you haven’t already connected to RStudio Connect then a window will pop up prompting you to connect. Click Next on this window\n\n\n\n\n\n\n\n\n\nClick Posit Connect\n\n\n\n\n\n\n\n\n\nEnter this URL into the box: https://dash-connect-prd.azure.defra.cloud/ and click Next\n\n\n\n\n\n\n\n\n\nAnother window will pop up prompting you to connect to R. Click on Connect\n\n\n\n\n\n\n\n\n\nAnother window will pop up saying ‘Connection succeeded’. Close this window\n\n\n\n\n\n\n\n\n\nOn the next window click Connect Account\n\n\n\n\n\n\n\n\n\n\n\n1.1.4.1.3 Publish Dashboard\nYou’ll be able to see now that you can publish from your account as this was set it for you. Now click Publish. If this screen appears just click Try Again.\n\n\n\n\n\n\n\n\n\nNavigate on the Connect server HERE where you will have your dashboard displayed.\n\n\n\n\n\n\n\n\n\nBy default a newly published dashboard can only be accessed by the publisher.\nPlease view the Dashboard admin to set access rights as seen in the picture.\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.4.2 Publishing from Python\nThis guide will walk through how to publish a dashboard onto the Posit Connect (Formerly RSConnect) server. This is currently supported from Azure Virtual Desktops. Whilst I focus on running commands from VS Code terminal from Workbench, I would also add extra commands that are necessary when working with VS Code as a standalone, from AVD which I marked them separately. The steps bellow would also work for JupyterLab when publishing from terminal.\n\n\n\n\n\n\nWarning\n\n\n\nBe aware JupyterLab isn’t configured with Databricks. I strongly advice publishing your Python apps from VS Code if you have data that is read from Databricks.\n\n\nActivate the virtual env if you work with virtual environment. I strongly advice to work with virtual environment - for more info check - Virtual Environment with Python . For the sake of showcasing I will create my virtual environment with this code\npython3 -m venv venv\nThen activate your virtual environment named venv.\nsource venv/bin/activate\nThere are a range of different ways to publish to the Posit server including Plotly DASH, Streamlit and Bokeh, Shiny, etc. There is a 2GB limit to the size of dashboards that can be published on the Posit Connect server.\n\nPloty DASHShiny for PythonStreamlitBokehVoilaNotebookQuarto\n\n\nPloty DASH is a python package for creating dashboards. To install DASH, run the following command in the command prompt:\npip install dash\n\n\nShiny for Python is a powerful web application framework for building interactive data visualizations, dashboards, and applications using Python. To install shiny run the following command in the command prompt:\npip install shiny\n\n\nStreamlit is a python package that makes it easy to build dashboards and custom web applications. To install Streamlit, run the following command in the command prompt:\npip install streamlit\n\n\nBokeh is an interactive visualization library which allows the construction of versatile graphics, and affords high-performance interactivity over large or streaming datasets. To install Bokeh, run the following command in the command prompt:\npip install bokeh\n\n\nVoilà allows you to convert a Jupyter Notebook into an interactive dashboard that allows you to share your work with others.\npip install voila\n\n\nJupyter notebooks can indeed also be published on Connect. Check for more information to the link - How to publish a jupyter notebook . But to install jupyter notebooks run the following command in the command prompt:\npip install rsconnect_jupyter\n\n\nQuarto allows you to interweave executable Python code with markdown to create dynamic documents, reports, websites, and presentations. Quarto provides a fully reproducible and flexible workflow for Python users\npip install quarto\n\n\n\nInstalling rsconnect\nYou will have to install “rsconnect” to publish a dashboard.\npip install rsconnect\n\n\n\n\n\n\nCaution\n\n\n\nThis is only for IDE’s outside of Workbench (e.g. standalone Visual Code in AVD)\nNote: these next steps aren’t needed for any IDE in Workbench\nTo run rsconnect outwith it’s location:\nset NEWPATH=C:\\Users\\XXXXXXXX\\AppData\\Roaming\\Python\\Python310\\Scripts\\\nReplacing the X’s with your system username. This is usually your employee number.\nThen:\nset PATH=%PATH%;%NEWPATH%\nNote: You will have to run both set commands above every time you close and reopen the command prompt.\n\n\n\n1.1.4.2.1 API key\nLog onto the Posit server with this link: https://dash-connect-prd.azure.defra.cloud/\nEnter your credentials.\nClick on your name and select API Keys from the menu bar that appears on the right hand side.\n\n\n\n\n\n\n\n\n\nClick on “+ new api key”\n\n\n\n\n\n\n\n\n\nGive it a name in the text box that pops up.\n\n\n\n\n\n\n\n\n\nThe second pop up gives you the chance to copy the 32 character alphanumeric code. Save this somewhere (for example in notepad) as you will require it later to publish and can be used for subsequent dashboards.\n\n\n\n\n\n\n\n\n\n\n\n1.1.4.2.2 Add API key to rsconnect\nTo configure the rsconnect package for the server:\nrsconnect add   --server https://dash-connect-prd.azure.defra.cloud/ --name \\&lt;name&gt; --api-key XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nWhere &lt;name&gt; is of your choice of the dashboard name and the X’s are replaced with your own API key.\n\n\n1.1.4.2.3 Deploy Dashboards\n\nPlotly DASHShiny for PythonStreamlitBokehVoilaNotebookQuarto\n\n\nNavigate to the folder that contains the folder that your dashboard files are located. For example if your dashboard files are contained within Workbench, then, the open the terminal in the VS Code / JupyterLab and navigate to the dash_app folder. Or if you are within ~/Desktop/dash_app/ then navigate to the /Desktop folder. Then run the bellow command in the command line:\nrsconnect deploy dash -n \\&lt;name&gt; \\&lt;foldername&gt;\nWhere &lt;name&gt; is replaced with the name you chose in the previous step, and &lt;foldername&gt; is the name of the folder containing you dashboard files.\nIn my case this is how it looks when running the above command for publishing dash app:\n\n\n\n\n\n\n\n\n\nAs you can see I have firstly activated my virtual env, then went into the actual folder using cd command. Installed all the needed libraries my app is dependent on with pip install. Then added my api key retrieved from Connect under my profile and deployed the app onto the server onto Posit Server.\n\n\nNavigate to the folder that contains the folder that your shiny dashboard files are located. For example is your dashboard files are located within Workbench, then open the terminal in VS Code /JupyterLab and navigate to shiny_app folder. Or if you are within ~/Desktop/shiny_app/ then navigate to the /Desktop folder.Then run the bellow command in the command line:\nrsconnect deploy shiny -n \\&lt;name&gt; \\&lt;foldername&gt;\nWhere &lt;name&gt; is replaced with the name you choose in the previous step, and &lt;foldername&gt; is the name of the folder containing your dashboard files. In my case this is how it looks when running the above command for publishing shiny python app:\n\n\n\n\n\n\n\n\n\nAs you can see I have firstly activated my virtual env, then went into the actual folder using cd command. Installed all the needed libraries my app is dependent on with pip install. Then added the url link https://dash-connect-prd.azure.defra.cloud/ and my api key retrieved from Connect under my profile and deployed the app onto the server onto Posit Server.\n\n\nNavigate to the folder that contains the folder that your dashboard files are located. For example is your dashboard files are located within Workbench, then open the terminal in VS Code /JupyterLab and navigate to streamlit_app folder. Or if you are within ~/Desktop/streamlit_app/ then navigate to the /Desktop folder.Then run the bellow command in the command line:\nrsconnect deploy streamlit -n \\&lt;name&gt; --entrypoint example.py &lt;foldername&gt;\nWhere &lt;name&gt; is replaced with the name you chose in the previous step, &lt;foldername&gt; is the name of the folder containing you dashboard files and example.py is the name of the python file containing your streamlit code.\nIn my case this is how it looks when running the above command for publishing streamlit app:\n\n\n\n\n\n\n\n\n\nAs you can see I have firstly activated my virtual env, then went into the actual folder using cd command. Installed all the needed libraries my app is dependent on with pip install. Then added the url link https://dash-connect-prd.azure.defra.cloud/ and my api key retrieved from Connect under my profile and deployed the app onto Connect server.\n\n\nNavigate to the folder that contains the folder that your dashboard files are located. For example is your dashboard files are located within Workbench, then open the terminal in VS Code /JupyterLab and navigate to bokeh_app folder. Or if you are within ~/Desktop/bokey_app/ then navigate to the /Desktop folder.Then run the bellow command in the command line:\nrsconnect deploy bokeh -n \\&lt;name&gt; --entrypoint example.py &lt;foldername&gt;\nWhere &lt;name&gt; is replaced with the name you chose in the previous step, &lt;foldername&gt; is the name of the folder containing you dashboard files and example.py is the name of the python file containing your bokeh code.\nIn my case this is how it looks when running the above command for publishing bokeh app:\n\n\n\n\n\n\n\n\n\nTest As you can see I have firstly activated my virtual env, then went into the actual folder using cd command. Installed all the needed libraries my app is dependent on with pip install. Then added the url link https://dash-connect-prd.azure.defra.cloud/ and my api key retrieved from Connect under my profile and deployed the app onto Connect server.\n\n\nNavigate to the folder that contains the folder that your dashboard files are located. For example is your dashboard files are located within Workbench, then open the terminal in VS Code /JupyterLab and navigate to voila_app folder. Or if you are within ~/Desktop/voila_app/ then navigate to the /Desktop folder.Then run the bellow command in the command line:\nrsconnect deploy voila -n &lt;name&gt; &lt;foldername&gt;\nWhere &lt;name&gt; is replaced with the name you chose in the previous step, &lt;foldername&gt; is the name of the folder containing you dashboard files and example.py is the name of the python file containing your bokeh code.\nIn my case this is how it looks when running the above command for publishing bokeh app:\n\n\n\n\n\n\n\n\n\nAs you can see I have firstly activated my virtual env, then went into the actual folder using cd command. Installed all the needed libraries my app is dependent on with pip install. Then added the url link https://dash-connect-prd.azure.defra.cloud/ and my api key retrieved from Connect under my profile and deployed the app onto Connect server.\n\n\nNavigate to the folder that contains the folder that your jupyter notebook files are located. For example is your jupyter notebook files are located within Workbench, then open the terminal in VS Code /JupyterLab and navigate to the folder where the notebook is. Or if you are within ~/Desktop/jupyter_app/ then navigate to the /Desktop folder.Then run the bellow command in the command line:\nrsconnect deploy notebook -n my_key ./name-of-the-jupyter_notebook.ipynb\nWhere &lt;name-of-the-jupyter_notebook&gt; is replaced with the name of your actual notebook.\nIn my case this is how it looks when running the above command for publishing bokeh app:\n\n\n\n\n\n\n\n\n\nAs you can see I have firstly activated my virtual env, then went into the actual folder using cd command. Installed all the needed libraries my app is dependent on with pip install. Then added the url link https://dash-connect-prd.azure.defra.cloud/ and my api key retrieved from Connect under my profile and deployed the app onto Connect server.\n\n\nNavigate to the folder that contains the folder that your quarto files are located. For example is your quarto dashboard files are located within Workbench, then open the terminal in VS Code /JupyterLab and navigate to quarto_app folder. Or if you are within ~/Desktop/quarto_app/ then navigate to the /Desktop folder.Then run the bellow command in the command line:\nrsconnect deploy voila -n &lt;name&gt; &lt;foldername&gt;\nWhere &lt;name&gt; is replaced with the name you chose in the previous step, &lt;foldername&gt; is the name of the folder containing you dashboard files and example.py is the name of the python file containing your bokeh code.\nIn my case this is how it looks when running the above command for publishing bokeh app:\n\n\n\n\n\n\n\n\n\nAs you can see I have firstly activated my virtual env, then went into the actual folder using cd command. Installed all the needed libraries my app is dependent on with pip install. Then added the url link https://dash-connect-prd.azure.defra.cloud/ and my api key retrieved from Connect under my profile and deployed the app onto Connect server.\n\n\n\n\n\n1.1.4.2.4 Shiny in Python (within RStudio IDE)\nAnother way to publish your dashboard to the Posit server is via Shiny in Python, within RStudio. Shiny for Python is a web application framework for Python.\nNote: When publishing a dashboard using Shiny in Python with RStudio, you need to use the command line tool as RStudio does not give you the publish button like it does when you have an RShiny app open.\nThe steps to deploy are the same as the methods listed above. In the command line, you need to install rsconnect, set both PATH and NEWPATH variables, create an API key on Posit, add the API key to rsconnect and then deploy by running the following command:\nrsconnect deploy shiny -n \\&lt;name&gt; \\&lt;foldername&gt;\n\n\n\n1.1.4.3 Publish Jupyter Notebooks (within AVD only)\nJupyter notebooks are very similar to Databricks notebooks. You can export a Databrick notebook to the jupyter notebook format. The file will have a .ipyn file extension.\nAlthough Jupyter can be installed on AVD. There is a version of rsconnect that can publish jupyter notebooks. There is also a plug in extension for jupyter notebooks that makes publishing very easy.\n\n1.1.4.3.1 Install requirements\nOpen a command prompt\n\n\n\n\n\n\n\n\n\nRun the following command:\npip install notebook rsconnect_jupyter jupyter_contrib_nbextensions\n\n\n1.1.4.3.2 Setting path to Python scripts\nAgain in the command prompt:\necho %USERNAME%\nThis gives your username to replace  in the following:\nset NEWPATH=C:\\Users\\&lt;USERNAME&gt;\\AppData\\Roaming\\Python\\Python310\\Scripts\nset PATH=%PATH%;%NEWPATH%\n\n\n1.1.4.3.3 Set up Jupyter extensions\nStill in the command prompt:\njupyter contrib nbextension install --user\njupyter nbextension enable varInspector/main\njupyter-nbextension install --py rsconnect_jupyter --user\njupyter-nbextension enable --py rsconnect_jupyter\njupyter-serverextension enable --py rsconnect_jupyter\njupyter notebook\nThe last command will open Jupyter in a browser.\n\n\n1.1.4.3.4 Opening/creating notebooks\nJupyter will open at the root of the AVD drive.\n\n\n\n\n\n\n\n\n\nBrowse to where you saved your .ipyn file and open it. Or if testing, open a new notebook and ether add some code or copy this example into the first cell and run it. You can also rename the new notebook by clicking on the default “Untitled” name.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = {'a': np.arange(50),\n        'c': np.random.randint(0, 50, 50),\n        'd': np.random.randn(50)}\ndata['b'] = data['a'] + 10 * np.random.randn(50)\ndata['d'] = np.abs(data['d']) * 100\n\nplt.scatter('a', 'b', c='c', s='d', data=data)\nplt.xlabel('entry a')\nplt.ylabel('entry b')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n1.1.4.3.5 Deploying Notebook\nBefore you publish a jupyter notebook, you will need to have previously logged into the DASH Connect server on the AVD.\nClick on the button with the blue symbol to the right of the windows decorations and select “Publish to Posit Connect”.\n\n\n\n\n\n\n\n\n\nIn the pop up window:\nServer Address\nhttps://dash-connect-prd.azure.defra.cloud/\nAPI key\nAdd you own API key created in the Posit server as shown in the Publishing Python guide.\nServer Name\nAdd a nickname of your choice.\nClick the “Add Server” button.\n\n\n\n\n\n\n\n\n\nIn the next pop up window you can edit the Tile if you wish and select the option that you prefer. Remember to add any additional files the notebook requires.\nClick the “Publish” button.\n\n\n\n\n\n\n\n\n\nIn the next pop up window select the radio button and click “Next”. This will return you to the previos window, click “Publish” again. You will see some output at the bottom of the windows and it will disappear once complete.\n\n\n1.1.4.3.6 View notebook on the Posit server\nNow when you log into the Posit server and click on the content tab you will see your notebook listed. Click on it and select the access settings you require. See the dashboard admin guide.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Posit Connect Server</span>"
    ]
  },
  {
    "objectID": "posit_connect.html#administration",
    "href": "posit_connect.html#administration",
    "title": "1  Posit Connect Server",
    "section": "1.2 Administration",
    "text": "1.2 Administration\nThe Posit Connect server has been deployed on a Virtual Machine (VM) within the DASH Platform. It enables users to set the visibility of content to either:\n\n1.2.1 Default settings\nWhen you access your dashboard for the first time, the settings on the right hand side are open on the “Access” tab. You can see that the radio buttons under “SHARING” as set to “Specific users or groups”. Under this in the “Who can view or change this Site” section is your own account name. This means that only you can view your dashboard.\n\n\n\n\n\n\n\n\n\n\n\n1.2.2 Setting dashboard access\nThe access radio buttons give three options:\n\nAnyone can access no login required. – Since the DASH Platform is restricted to Defra group IP this will release content to anyone working on the Defra Group IP. (No Posit Connect account required)\nAll users – This will allow anyone with a RStudio Connect log in to view the content.\nOnly specified RStudio connect users – This releases content to specified RStudio Connect users. You can set the list of users that are able to access the dashboard. The users must have been on the server previously for their username (email address) to appear.\n\nIf you require restricted content access for non-DASH users e.g. senior leadership, please plan well in advance for this. When licences are no longer required please raise an issue in the DASH issue tracker (see the support section) to request these licences be revoked and returned to the pool for other users.\nDo not forget to click on the “save” pop up near the top of the side menu.\n\n\n1.2.3 Collaboration\nUsers can be set as viewers or collaborators. Collaborators are able to update the dashboard. For a collaborator to successfully update a posit app, the original publisher must include the rsconnect connect folder (that includes a .json file) in GitHub tracking. Further details can be found here: Dashboard collaboration\n\n\n1.2.4 Collaboration on Python (VS Code)\n\n1.2.4.1 Main User\n\nPublish to Posit via Python method.\nAfter publishing for the first time, this creates a rsconnect folder in your project. This stores deployment-related metadata and configuration for applications that are developed.\nCommit and push these changes to the GitHub repo.\nIn Posit, under SHARING, add your collaborators by their email address and switch their access from ‘Viewer’ to ‘Collaborator’ in the bar on the right-hand side. Click save.\nPublish project to GitHub and ensure that they also have access to the GitHub project.\n\n\n\n\n\n\n\n\n\n\n\n\n1.2.4.2 Collaborator\n\nCheck that the GitHub repo contains a rsconnect folder.\nClone the GitHub project into RStudio.\nCheck that the name of the parent folder is the same as the original.\nWork on the project as normal and when publishing this should update the existing Posit app.\n\n\n\n\n1.2.5 Collaboration on RStudio\n\n1.2.5.1 Main User\n\nPublish the RShiny app to Posit via R method.\nAfter publishing for the first time, this creates a rsconnect folder in your project.\nCommit and push these changes to the GitHub repo.\nOn Posit, under SHARING, add your collaborators by their email address and switch their access from ‘Viewer’ to ‘Collaborator’. Click save.\nEnsure that they also have access to the GitHub project.\n\n\n\n1.2.5.2 Collaborator\n\nCheck that the GitHub repo contains a rsconnect folder.\nClone the GitHub project into RStudio.\nWork on the project as normal and when publishing this should update the existing Posit app.\n\n\n\n\n1.2.6 Set a vanity URL\nOn the same menu bar you can also set a vanity URL. This gives a friendlier address to share. In the text box type the name you want to be the extension of the URL.\nEG Typing “myfirstdash” will give a URL to reach the dashboard of https://dash-connect-prd.azure.defra.cloud//myfirstdash\nAgain do not forget to click on the save popup.\nThere is also a “copy me” button to put the new URL in you clipboard ready to be pasted and shared.\n\n\n1.2.7 Setting Environmental Vairables\nEnvironmental variables to be used by the published content can be set in “Vars” tab in the settings menu.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Posit Connect Server</span>"
    ]
  },
  {
    "objectID": "posit_connect.html#posit-api",
    "href": "posit_connect.html#posit-api",
    "title": "1  Posit Connect Server",
    "section": "1.3 Posit API",
    "text": "1.3 Posit API\nThe Posit API can be used to perform actions on the Posit Connect server remotely. Eg Databricks, AVD or Laptop. It can also be used within a published application for example to display useage statisics or set user access.\nThe API can be use with your API package of choice. eg BASH - curl, Python - Request or R - httr/httr2. However, you may find it easier to use the posit-sdk package for Python and connectapi package for R.\nTo use the API you have to give the package both the URL of the Posit Connect server url and your own API key. These can be hard coded but for security it is advised to set environmental variables for both.\neg.\nCONNECT_SERVER = ‘https://dap-prd2-connect.azure.defra.cloud/’ (Our server)\nCONNECT_API_KEY = ‘***********07Xs’ (Not an active API Key)",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Posit Connect Server</span>"
    ]
  },
  {
    "objectID": "posit_connect.html#faqs",
    "href": "posit_connect.html#faqs",
    "title": "1  Posit Connect Server",
    "section": "1.4 FAQs",
    "text": "1.4 FAQs\n\n1.4.1 Dashboard fails to run locally\nTraining for Shiny and Plotly is available on Datacamp.\nGeneral advice for dashboard development is to start small and build up, testing regularly.\nCheck online sources such as stackoverflow for solutions.\nTry posting in the Data-science-Defra-community teams group.\nThere are limits to the direct support the DASH team can give. Please do not expect us to fix the code of a broken dashboard.\n\n\n1.4.2 Dashboard fails to run on DASH\nIf you believe the dashboard is failing to run due to the DASH environment raise a ticket on the Dash Platform Resolution tracker.\nPlease include a full description of the problem, troubleshooting steps taken and attach relevant files. That could be screenshots (or from snip tool), code or error text.\n\n\n1.4.3 Dashboard fails to publish\nIf your dashboard is working locally or on DASH but fails to deploy to the Posit server, try these steps:\n\nCheck deployment logs to determine at what point it fails. You may have to scroll up through them to find the first point of failure. Include the full deployment log with any support request.\nUse a minimal working dashboard (eg the hello world examples). However, include the packages that you require to import for the more complex dashboard. The posit server will attempt to recreate your environment. This will eliminate any code problems and make the problem easier to try to replicate by support.\nRemove any package indicated as failure point in deployment log. If this is not clear, add/remove packages until you can determine the package causing the problem.\nTry updating a failing package, and it dependencies. This could also be packages required to compile packages. eg Rcpp\n\n\n\n1.4.4 Dashboard published but fails to run on the Posit server\nIf a dashboard deployment appears to work but fails to run on the server.\n\nCheck to see you are changing the working directory in your code.\nTry commenting out access to data or other files in the code. eg loading csv files, API requests or even images.\n\nFuther troubleshooting can be found on the Posit website troubleshooting website.\n\n\n1.4.5 Unable to asign Dashboard to user that has been given access to the Posit server\nUsers given access to the Posit server must log in at least once before there account will be created and dashboard access granted by publishers.\n\n\n1.4.6 Users unable to log into Posit server after first log in.\nThe Posit server creates a username from the email address you entered on first log in. This is not case sensitive however all subsequent then become case sensitive. In other words, your email/username must be entered with the same capitalisation as the first time. We suggest using all lowercase.\n\n\n1.4.7 Viewing the dashboard on Posit\nReturn to the Posit server: https://dash-connect-prd.azure.defra.cloud/\nClick on “Content” on the left hand side. You should see your dashboard in the list named as you chose and your username under Author. Click on it and you will see your dashboard.\nPlease see the tutorial on dashboard admin to apply settings to your dashboard.",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Posit Connect Server</span>"
    ]
  },
  {
    "objectID": "posit_connect.html#migration-of-apps-from-old-posit-connect-to-new-posit-connect",
    "href": "posit_connect.html#migration-of-apps-from-old-posit-connect-to-new-posit-connect",
    "title": "1  Posit Connect Server",
    "section": "1.5 Migration of Apps from old Posit Connect to New Posit Connect",
    "text": "1.5 Migration of Apps from old Posit Connect to New Posit Connect\nThe present guideline purpose is to aide the migration of R & Python apps from old Connect server to the new Connect Server.\nThe new Connect Server, where all apps need to be migrated to is found at this link - https://dash-connect-prd.azure.defra.cloud/.\nMake sure you create an API Key the new Connect server so that you’ll be able to migrate your app. See API key on how to get one.\nThe old Connect server is found at this link - https://dap-prd2-connect.azure.defra.cloud/.\nThe old Connect server will be decommissioned at a certain point in time, therefore, it is important that all the apps are migrated from old connect server to the new connect server within the month of October.\n\n1.5.1 Methods for migration of apps\nThere are several methods to migrate your app from old Connect to the new Connect.\nThis is a summary table of five methods of migration.The best methods for fast migration are the first three methods, with low and medium complexity, the last two are high complexity with advantages for each method - see Decision tree. Method E approach is available only at mid-end of October month (2025), as licences for Workbench would be available then. Therefore, if method E is your choice for migration, then wait until mid-end of October.\n\n\n\n\n\n\n\n\n\n\n1.5.1.0.1 Decision tree\nDecision tree helps you with choosing which migration fits your need.\n\n\n\n\n\n\n\n\n\n\n\n1.5.1.1 Method A: Direct Deployment from your current IDE\nThis method assumes you are RStudio in Databricks and Python VS Code but with a small different you publish onto new Connect server rather the old one. See section bellow on relevant steps Publishing from RStudio and Publishing from Python.\nYou need an API key to be created within new Connect Server. See here API key how to create an API key.\n\n\n1.5.1.2 Method B - Github URL link\nUsing Github URL link to publish onto new Connect; this has the advantage of not needing to open any R / Python and IDE.\nYou need an API key to be created within new Connect Server. See here API key how to create an API key.\n\n\n\n\n\n\nCaution\n\n\n\nThis method implies you have manifest.json already pushed to your repository onto Github. If you do not have this file follow section Writing Manifest json in R and Python\n\n\nSteps\nAssuming you have your project pushed to Github, follow the next steps\n\nCopy to clipboard the url link\n\n\n\n\n\n\n\n\n\n\n\nChoose Import from Git from Publish button\n\n\n\n\n\n\n\n\n\n\n\nAdd the Git repository URL into the box\n\n\n\n\n\n\n\n\n\n\n\nCheck list is good. Click Next\n\n\n\n\n\n\n\n\n\n\n\nChoose which branch, for more branches click down arrow and you’ll be able to see all the branches from github. I have the main branch\n\n\n\n\n\n\n\n\n\n\n\nI do not have manifest.json file therefore cannot migrate the app and will follow the 8th step. If you do have manifest.json file then app should be migrated on new Connect. If you do not have manifest.json follow the steps here - Writing Manifest json in R and Python\n\n\n\n\n\n\n\n\n\n\n\nThe app was migrated on the new Connect as it can be seen in the picture bellow.\n\n\n\n\n\n\n\n\n\n\n\n\n1.5.1.3 Method C - Promote function\nYou need an API key to be created within new Connect Server. See here API key how to create an API key.\nSteps\nFor this method you need to have:\nA. 2 api keys: from the old connect and from new connect (have them at hand)\nB. the 2 URL’s, the new and old connect servers:\n\nis the old connect server - https://dap-prd2-connect.azure.defra.cloud/\nand here is the new connect server - https://dash-connect-prd.azure.defra.cloud/\n\nC. the name of the app from the old connect server - this needs to be added into the code.\nAlso you need to install connectapi library within your RStudio session and pass all the parameters needed to it. Copy the code bellow with:\n# Need to pin to 0.7.0 due to breaking change for version of Connect on old server.\nrequire(remotes)\ninstall_version(\"connectapi\", version = \"0.7.0\")\n\nlibrary(connectapi)\n\npromote('https://dap-prd2-connect.azure.defra.cloud/', 'https://dash-connect-prd.azure.defra.cloud/', 'new_connectserver_api_key','old_connectserver_api_key', '&lt;name&gt;')\n\n\n1.5.1.4 Method D - Download - Upload bundle\nThis method might apply well to those apps where users left Defra. The apps are in the supervision of others users. The advantage of this method is that the download of the bundle from old Connect server and uploading it within your IDE, allows you to reproduce the same environment of the app.\nYou need an API key to be created within new Connect Server. See here API key how to create an API key.\nSteps\n\nGo to old connect - https://dap-prd2-connect.azure.defra.cloud/\nGo onto your app amd download the bundle. Just like in the picture\n\n\n\n\n\n\n\n\n\nUpload it onto any IDE (RStudio/VS Code) or Workbench\nFor next steps, follow sections Publishing from RStudio & Publishing from Python.\n\n\n\n\n\n\nTip\n\n\n\nA note of advice is upload the bundle straight into Workbench, either within RStudio or VS Code and download all the needed libraries and versions of the app. Test the app works the way is intended and then migrate it.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nIf your app is based on updated data in Databricks, VS Code on Workbench is the perfect IDE to be used in this instance. JupyterLab isn’t configured with Databricks.\n\n\n\n\n\n1.5.1.5 Method E: Full project migration via Workbench\nThis method requires first a transfer of the whole code and files onto Workbench - see steps here Migration-of-projects-to-workbench within section Posit Workbench. After you have migrated your code and all the files to Workbench follow the migration just as documented at sections Publishing from RStudio & Publishing from Python . This method advantage is you have all your your files transferred alongside migration task onto new Connect.\nWithin the Posit Workbench make sure you select the R & Python versions as the same as within the original environment. Otherwise, the code has to be re-factored with the newer versions of R provided. The same applies to Python and Quarto.\n\n\n\n\n\n\nNote\n\n\n\nThe versions of each software in the new environment are:\n\nR = “4.4.2” “4.4.0” “4.3.2” “4.2.2”\nPython = “3.12.3” “3.11.11” “3.10.12”\nQuarto =“1.7.31” “1.6.42” “1.5.54”\n\n\n\nYou need an API key to be created within new Connect Server. See here API key how to create an API key.\nSteps\n\nAccess the old Connect where the app is - https://dap-prd2-connect.azure.defra.cloud\n\n\n\n\n\n\n\n\n\n\n\nPress Download. This is a tar file - this might need to be unzipped and zipped to a non-tar file again.\n\n\n\n\n\n\n\n\n\n\n\nOpen RStudio and press File to upload. Choose the zipped file not the tar file.\n\n\n\n\n\n\n\n\n\n\nAfter you have finished the above steps, go to section Publishing from RStudio and Publishing from Python to finish the migration of your app.\n\n\n1.5.1.6 Writing Manifest json in R and Python\n\nFor R appsFor Python apps\n\n\na. open RStudio and install rsconnect. Restart session for the changes to occur.\nb. within the console run the command bellow.\nrsconnect::writeManifest()\n\n\nIf manifest.json file isn’t available, then:\n\nopen the Python on whatever IDE you’ve worked on\nopen the terminal\nnavigate to your project folder\nmake sure you have the right Python version on which app was developed and right version of libraries.\n\nMake sure you have everything needed for the manifest.json to be written, otherwise some issues may come up during the publishing.\n\nin the terminal we need to write the manifest json depending on the type of app you have. I will showcase for mainstream ones but for more info check the following link - https://docs.posit.co/rsconnect-python/commands/write-manifest/\nafter writing the manifest.json make sure you push to github the new file and restart the process of publishing onto new Connect.\n\nPress next tabs to copy code for writing the manifest.json files for different python products.\n\n\n\n\nQuarto - PythonShiny - PythonStreamlit - PythonBokeh - PytonFlask - PythonDash - PythonNotebookApi - Python\n\n\nOpen terminal. Make sure you are within your project for the bellow code to work. Otherwise, run second command according to the pattern shown in the code, by replacing OPTIONS AND DIRECTORY with your own Directory\nrsconnect write-manifest quarto ./\nwrite-manifest quarto [OPTIONS] DIRECTORY [EXTRA_FILES]...\n\n\nwrite-manifest shiny [OPTIONS] DIRECTORY [EXTRA_FILES]...\n\n\nwrite-manifest streamlit [OPTIONS] DIRECTORY [EXTRA_FILES]...\n\n\nwrite-manifest bokeh [OPTIONS] DIRECTORY [EXTRA_FILES]...\n\n\nwrite-manifest flask [OPTIONS] DIRECTORY [EXTRA_FILES]...\n\n\nwrite-manifest dash [OPTIONS] DIRECTORY [EXTRA_FILES]...\n\n\nwrite-manifest notebook [OPTIONS] DIRECTORY [EXTRA_FILES]...\n\n\nwrite-manifest api [OPTIONS] DIRECTORY [EXTRA_FILES]...",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Posit Connect Server</span>"
    ]
  },
  {
    "objectID": "posit_connect.html#section",
    "href": "posit_connect.html#section",
    "title": "1  Posit Connect Server",
    "section": "1.6 ",
    "text": "1.6",
    "crumbs": [
      "Posit",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Posit Connect Server</span>"
    ]
  }
]